{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåä Neural Network Training for Nanofluid Prediction (Google Colab)\n",
    "\n",
    "This notebook is optimized for **Google Colab**. Follow the setup instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì§ Step 1: Upload Your Data\n",
    "\n",
    "You have **3 options**:\n",
    "\n",
    "### Option A: Upload Files Manually\n",
    "1. Click the **folder icon** üìÅ in the left sidebar\n",
    "2. Create folder structure: `data/processed/`\n",
    "3. Upload `train_dataset.csv` and `test_dataset.csv`\n",
    "\n",
    "### Option B: Mount Google Drive (Recommended)\n",
    "Run the cell below and follow prompts\n",
    "\n",
    "### Option C: Upload from GitHub\n",
    "Clone the repo directly (see Alternative Setup below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION B: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Upload your NANO-FLUIDS folder to Google Drive first\n",
    "# Then uncomment and modify this path:\n",
    "# %cd /content/drive/MyDrive/NANO-FLUIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION C: Clone from GitHub\n",
    "!git clone https://github.com/BhaveshBytess/NANOFLUIDS.git\n",
    "%cd NANOFLUIDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (most are pre-installed in Colab)\n",
    "!pip install -q torch scikit-learn pandas numpy matplotlib seaborn\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 3: Load Data and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ========================================\n",
    "# CONFIGURE PATHS BASED ON YOUR SETUP\n",
    "# ========================================\n",
    "\n",
    "# If you cloned from GitHub (Option C):\n",
    "DATA_DIR = Path(\"data/processed\")\n",
    "ARTIFACT_DIR = Path(\"models\")\n",
    "\n",
    "# If you uploaded manually (Option A):\n",
    "# DATA_DIR = Path(\"/content/data/processed\")\n",
    "# ARTIFACT_DIR = Path(\"/content/models\")\n",
    "\n",
    "# If using Google Drive (Option B):\n",
    "# DATA_DIR = Path(\"/content/drive/MyDrive/NANO-FLUIDS/data/processed\")\n",
    "# ARTIFACT_DIR = Path(\"/content/drive/MyDrive/NANO-FLUIDS/models\")\n",
    "\n",
    "TRAIN_PATH = DATA_DIR / \"train_dataset.csv\"\n",
    "TEST_PATH = DATA_DIR / \"test_dataset.csv\"\n",
    "FEATURES = [\"M\", \"S\", \"K\", \"phi1\", \"phi2\", \"Ec\", \"Pr\", \"eta\"]\n",
    "TARGETS = [\"f3\", \"f5\"]\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Verify files exist\n",
    "if not TRAIN_PATH.exists():\n",
    "    print(f\"‚ùå ERROR: {TRAIN_PATH} not found!\")\n",
    "    print(f\"Current directory: {Path.cwd()}\")\n",
    "    print(f\"Files in current directory:\")\n",
    "    !ls -la\n",
    "else:\n",
    "    print(f\"‚úÖ Found training data at {TRAIN_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "X_full = train_df[FEATURES].to_numpy(dtype=float)\n",
    "y_full = train_df[TARGETS].to_numpy(dtype=float)\n",
    "X_test = test_df[FEATURES].to_numpy(dtype=float)\n",
    "y_test = test_df[TARGETS].to_numpy(dtype=float)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_full,\n",
    "    y_full,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data loaded successfully!\")\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Val:   {X_val.shape}\")\n",
    "print(f\"  Test:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 4: Define Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanofluidDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class NanofluidNet(nn.Module):\n",
    "    def __init__(self, input_dim=8, hidden1=64, hidden2=128, hidden3=64, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, hidden3)\n",
    "        self.fc4 = nn.Linear(hidden3, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "print(\"‚úÖ Model architecture defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Step 5: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "X_mean = X_train.mean(axis=0)\n",
    "X_std = X_train.std(axis=0)\n",
    "X_train_norm = (X_train - X_mean) / X_std\n",
    "X_val_norm = (X_val - X_mean) / X_std\n",
    "X_test_norm = (X_test - X_mean) / X_std\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = NanofluidDataset(X_train_norm, y_train)\n",
    "val_dataset = NanofluidDataset(X_val_norm, y_val)\n",
    "test_dataset = NanofluidDataset(X_test_norm, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "model = NanofluidNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"‚úÖ Training setup complete\")\n",
    "print(f\"  Model parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 200\n",
    "patience = 40\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"üèãÔ∏è Starting training...\")\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), ARTIFACT_DIR / \"neural_network.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\n‚úÖ Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nüéâ Training complete! Best val loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 6: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(ARTIFACT_DIR / \"neural_network.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        y_pred.append(outputs.cpu().numpy())\n",
    "\n",
    "y_pred = np.vstack(y_pred)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_f3 = mean_absolute_error(y_test[:, 0], y_pred[:, 0])\n",
    "mae_f5 = mean_absolute_error(y_test[:, 1], y_pred[:, 1])\n",
    "rmse_f3 = np.sqrt(mean_squared_error(y_test[:, 0], y_pred[:, 0]))\n",
    "rmse_f5 = np.sqrt(mean_squared_error(y_test[:, 1], y_pred[:, 1]))\n",
    "r2_f3 = r2_score(y_test[:, 0], y_pred[:, 0])\n",
    "r2_f5 = r2_score(y_test[:, 1], y_pred[:, 1])\n",
    "\n",
    "print(\"üìä TEST SET RESULTS:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"f3 (velocity gradient):\")\n",
    "print(f\"  MAE:  {mae_f3:.4f}\")\n",
    "print(f\"  RMSE: {rmse_f3:.4f}\")\n",
    "print(f\"  R¬≤:   {r2_f3:.4f}\")\n",
    "print(f\"\\nf5 (temperature gradient):\")\n",
    "print(f\"  MAE:  {mae_f5:.4f}\")\n",
    "print(f\"  RMSE: {rmse_f5:.4f}\")\n",
    "print(f\"  R¬≤:   {r2_f5:.4f}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'normalization': {\n",
    "        'mean': X_mean.tolist(),\n",
    "        'std': X_std.tolist()\n",
    "    },\n",
    "    'metrics': {\n",
    "        'test_mae_f3': float(mae_f3),\n",
    "        'test_mae_f5': float(mae_f5),\n",
    "        'test_rmse_f3': float(rmse_f3),\n",
    "        'test_rmse_f5': float(rmse_f5),\n",
    "        'test_r2_f3': float(r2_f3),\n",
    "        'test_r2_f5': float(r2_f5)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(ARTIFACT_DIR / \"neural_network_metadata.json\", 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Model saved to:\", ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 7: Download Trained Model\n",
    "\n",
    "Download the model files to use them locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download(str(ARTIFACT_DIR / \"neural_network.pt\"))\n",
    "files.download(str(ARTIFACT_DIR / \"neural_network_metadata.json\"))\n",
    "\n",
    "print(\"‚úÖ Files ready for download!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
